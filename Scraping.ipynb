{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scrap data from __[FBref.com](https://fbref.com/en/)__\n",
    "Tutorial loosely followed: [Tutorial](https://medium.com/analytics-vidhya/intro-to-scraping-basketball-reference-data-8adcaa79664a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install cchardet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Necassary Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np  #load up the libraries and object definitions we need\n",
    "import pandas as pd\n",
    "from pandas import DataFrame, Series\n",
    "import io\n",
    "from string import ascii_lowercase\n",
    "import lxml\n",
    "import requests\n",
    "\n",
    "import cchardet\n",
    "\n",
    "\n",
    "# load up my visualization system, and call the object plt\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# tell ipython notebook to print visualizations inline\n",
    "%pylab\n",
    "%matplotlib inline\n",
    "\n",
    "from urllib.request import urlopen\n",
    "from bs4 import BeautifulSoup, SoupStrainer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Beautiful Soup is used for all scraping\n",
    "For each season, Fb ref has a page for all players who in the top leagues. For each year, go to the correct url and get all anchor tags that has a href that matches the regular expression for a player's page. All get each player's nation and birth year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "players = []\n",
    "playersdf = pd.DataFrame()\n",
    "years = [\"2010-2011\", \"2011-2012\",\"2012-2013\",\"2013-2014\",\"2014-2015\",\"2015-2016\",\"2016-2017\",\"2017-2018\",\"2018-2019\",\"2019-2020\",\"2020-2021\",\"2021-2022\",\"2022-2023\"]\n",
    "for y in years:\n",
    "  #for c in pages:\n",
    "  product = SoupStrainer('div',{'id': 'div_stats_standard'})\n",
    "  print(product)\n",
    " \n",
    "  html = urlopen(\"https://fbref.com/en/comps/Big5/\" + y + \"/stats/players/\" + y + \"-Big-5-European-Leagues-Stats\")\n",
    "  \n",
    "    #url4 = \"https://fbref.com/en/players/\" + c + \"/\"\n",
    "    #print(url4)\n",
    "    # collect HTML data\n",
    "  #html = urlopen(url4)\n",
    "  soup2 = BeautifulSoup(html, 'lxml', parse_only=product)\n",
    "  #soup2 = soup.find(id=\"div_stats_standard\")\n",
    "  #soup2\n",
    "  headers = [th.getText() for th in soup2.findAll('tr', limit=2)[1].findAll('th')]\n",
    "  headers.pop(0)\n",
    "\n",
    "  rows = soup2.findAll('tr')[2:]\n",
    "  rows_data = [[td.getText() for td in rows[i].findAll('td')]\n",
    "                      for i in range(len(rows))] \n",
    "\n",
    "  # print(headers)\n",
    "  # print(rows_data) \n",
    "\n",
    "  df = pd.DataFrame(rows_data, columns = headers)\n",
    "  dffinal = df[['Nation', 'Born']]\n",
    "  # dffinal = dffinal.iloc[:, :-1]\n",
    "  #dffinal.drop(dffinal.columns[len(dffinal.columns)-1], axis=1, inplace=True)\n",
    "  df2 = dffinal[dffinal.Born.notnull()]\n",
    "  #df2 = df2.fillna('na Na')\n",
    "  df2.replace(to_replace=[\"\"], value='na Na', inplace=True)\n",
    "  df2.replace(to_replace=[\" SCG\"], value='na SCG', inplace=True)\n",
    "  df2.replace(to_replace=[\" MCO\"], value='na MCO', inplace=True)\n",
    "  if y == '2012-2013':\n",
    "    df2.drop(df2.tail(1).index,inplace=True)\n",
    "  if y == '2013-2014':\n",
    "    df2.drop(df2.tail(3).index,inplace=True)\n",
    "  if y == '2014-2015':\n",
    "    df2.drop(df2.tail(3).index,inplace=True)\n",
    "  if y == '2016-2017':\n",
    "    df2.drop(df2.tail(2).index,inplace=True)\n",
    "  if y == '2017-2018':\n",
    "    df2.drop(df2.tail(1).index,inplace=True)\n",
    "  #print(df2['Nation'])\n",
    "  df2['Nation'] = [x.split()[1] for x in df2['Nation']]\n",
    "  #df2 = df2[df2.Age != '']\n",
    "    # create beautiful soup object from HTML\n",
    "  #soup = BeautifulSoup(html, 'html.parser')\n",
    "    #uncomment to see HTML\n",
    "  #soup2 = soup.find(class_=\"section_wrapper\")\n",
    "  print(y)\n",
    "  players = []\n",
    "  for link in soup2.find_all('a'):\n",
    "      #html2 = urlopen(\"https://fbref.com\" + link.get('href'))\n",
    "      #soup2 = BeautifulSoup(html2, 'html.parser')\n",
    "      #if(soup2.findAll(text='var sr_gender = \"men\";') != []):\n",
    "      if(re.search(r\"[a-z]{7}[/]{1}[a-h0-9]{8}[\\/]{1}[a-zA-Z-]{2,50}$\",link.get('href')) != None):\n",
    "        players.append(\"https://fbref.com\" + link.get('href'))\n",
    "        # nameInt = x.rfind('/')\n",
    "        # name = x[(nameInt+1):]\n",
    "        # id = x[(nameInt-8):nameInt]\n",
    "        # players.append(x)\n",
    "  \n",
    "  # for p in players:\n",
    "  #   print(p)\n",
    "  df2['id'] = players\n",
    "  playersdf = playersdf.append(df2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "playersdf.replace(to_replace=[\" MCO\"], value='na MCO', inplace=True)\n",
    "#playersdf['Nation'] = [x.split()[1] for x in playersdf['Nation']]\n",
    "playersdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remove all duplicate players who had played more than 1 year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = playersdf.drop_duplicates()\n",
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "playersList = df2['id'].tolist()\n",
    "playersBirth = df2['Born'].tolist()\n",
    "playersNation = df2['Nation'].tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Go to each players page, get their domestic stats, 1 row for each season they have played. Append to a dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "with warnings.catch_warnings():\n",
    "    warnings.simplefilter('ignore')\n",
    "    i = 0\n",
    "    playersdf = pd.DataFrame()\n",
    "    for x in playersList:\n",
    "      #print(x)\n",
    "      # html = urlopen(x)\n",
    "      # soup = BeautifulSoup(html, features=\"lxml\")\n",
    "      # soup1 = soup.find(id=\"div_stats_standard_dom_lg\")\n",
    "\n",
    "      product = SoupStrainer('div',{'id': 'div_stats_standard_dom_lg'})\n",
    "      #print(product)\n",
    "      soup1 = BeautifulSoup(requests.get(x).content,'lxml', parse_only=product)\n",
    "\n",
    "      \n",
    "        #print(soup1)\n",
    "      if(soup1 != None):# and (soup.findAll(text='var sr_gender = \"men\";') != [])):\n",
    "          #print(soup1)\n",
    "          #print(\"Hi\")\n",
    "        headers = [th.getText() for th in soup1.findAll('tr', limit=2)[1].findAll('th')]\n",
    "        headers\n",
    "        headers.pop(0)\n",
    "        #gets name of player from URL\n",
    "        nameInt = x.rfind('/')\n",
    "        name = x[(nameInt+1):]\n",
    "        id = x[(nameInt-8):nameInt]\n",
    "        #print(name)\n",
    "        # get rows from table\n",
    "        rows = soup1.findAll('tr')[2:]\n",
    "        rows_data = [[td.getText() for td in rows[i].findAll('td')]\n",
    "                            for i in range(len(rows))]\n",
    "\n",
    "        #print(rows_data)\n",
    "        # if you print row_data here you'll see an empty row\n",
    "        # so, remove the empty row\n",
    "        season = soup1.findAll('tr')[2:]\n",
    "        season = [[th.getText() for th in rows[i].findAll('th')]\n",
    "                            for i in range(len(rows))]\n",
    "        #rows_data.pop(20)\n",
    "        #div_stats_standard_dom_lg\n",
    "        # for simplicity subset the data for only 39 seasons\n",
    "        #rows_data = rows_data[0:38]\n",
    "\n",
    "\n",
    "        #print(season)\n",
    "        s1 = []\n",
    "        s2 = []\n",
    "        for s in season:\n",
    "          s1.append(s[0])\n",
    "          s2.append(re.search(r\"^[0-9-]{4,9}$\",s[0]) != None)\n",
    "\n",
    "        #for s in s1:\n",
    "          #print(re.search(r\"^[0-9-]{4,9}$\",s) != None)\n",
    "          \n",
    "          \n",
    "        df = pd.DataFrame(rows_data, columns = headers)\n",
    "        #df = pd.DataFrame(rows_data)\n",
    "        df['Season'] = s1\n",
    "        df['tf'] = s2\n",
    "        df['Name'] = name\n",
    "        df['ID'] = id\n",
    "        df['Nation'] = playersNation[i]\n",
    "        df['Birth Year'] = playersBirth[i]\n",
    "        #indexNames = df[ re.search(r\"^[0-9-]{4,9}$\",df['seasons']) != None ].index\n",
    "        #df.drop(indexNames , inplace=True)\n",
    "        #print(name)\n",
    "        dfnew = df.loc[df['tf'] == True]\n",
    "        dffinal = dfnew[['Season', 'Squad', 'Comp', 'Country','Name', 'ID', 'Birth Year', 'Nation', 'LgRank' ,'MP','Gls']]\n",
    "        dffinal = dffinal.iloc[:, :-1]\n",
    "        #df5 = dffinal.assign(Name=id)\n",
    "        # dffinal['ID']= id\n",
    "        #dffinal\n",
    "        playersdf = playersdf.append(dffinal)\n",
    "\n",
    "        print(i)\n",
    "        i += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "playersdf.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "export file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "playersdf.to_csv('playersHistory.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "ce21b655b4d6c9e397d5ad93d5666c623f49909f6d0cc2f72076dafcf1b3ecfb"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
